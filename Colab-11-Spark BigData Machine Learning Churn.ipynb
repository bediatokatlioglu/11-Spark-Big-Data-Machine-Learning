{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bde1865",
   "metadata": {
    "id": "5bde1865"
   },
   "source": [
    "<img src=\"PySpark.avif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311fe80",
   "metadata": {
    "id": "4311fe80"
   },
   "source": [
    "### Spark ve PySpark Nedir?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c069f6",
   "metadata": {
    "id": "34c069f6"
   },
   "source": [
    "Apache Spark, büyük veri işleme ve analizi için kullanılan açık kaynaklı bir veri işleme çerçevesidir. Spark, büyük veri kümelerini hızlı, paralel ve dağıtık bir şekilde işlemek, analiz etmek ve modellemek için tasarlanmıştır.\n",
    "\n",
    "PySpark ise, büyük veri işleme ve analizi için kullanılan Apache Spark'ın Python API'sidir. Spark, dağıtık veri işleme, yüksek performanslı hesaplama ve büyük veri analizi için tasarlanmış bir açık kaynaklı bir veri işleme çerçevesidir. PySpark ise Python programlama diliyle Spark platformuna erişim sağlayan bir kütüphanedir. İşte PySpark'ın temel özellikleri:\n",
    "\n",
    "1. **Dağıtık İşleme:** Spark, büyük veri kümelerini parçalara ayırarak ve bu parçaları birden fazla bilgisayar üzerinde işleyerek paralel işlem yapabilir. Bu sayede işlemler daha hızlı ve ölçeklenebilir hale gelir.\n",
    "\n",
    "2. **Yüksek Hız:** Spark, veriyi bellekte (RAM) tutarak işlem yapar. Bu, geleneksel disk tabanlı veri işleme sistemlerine göre çok daha hızlı sonuçlar elde etmenizi sağlar.\n",
    "\n",
    "3. **Çeşitli Veri Kaynakları:** PySpark, çeşitli veri kaynaklarına (CSV, JSON, Parquet, Hive, HBase vb.) erişim sağlar ve bu verileri Spark veri yapıları olan RDD (Resilient Distributed Dataset) veya DataFrame formatında işleyebilirsiniz.\n",
    "\n",
    "4. **Yüksek Seviyeli API:** PySpark, Python programlama dilini kullandığı için kullanımı kolaydır ve geniş bir Python topluluğu tarafından desteklenir. Bu, geliştirme süreçlerini hızlandırır.\n",
    "\n",
    "5. **Makine Öğrenimi ve Büyük Veri Analizi:** Spark, geniş bir veri işleme kütüphanesine sahiptir. PySpark üzerinden Spark MLlib'i kullanarak makine öğrenimi modelleri oluşturabilir ve büyük veri kümesi üzerinde analizler yapabilirsiniz.\n",
    "\n",
    "6. **Dağıtık Veri Setleri:** Spark, RDD ve DataFrame gibi yapılarla veriyi temsil eder. Bu yapılar, işlemlerinizi paralel olarak işlemek için kullanılır.\n",
    "\n",
    "7. **Veri Akışı:** Spark Streaming, gerçek zamanlı veri akışını işlemek için kullanılan bir modüldür. Bu sayede veri akışlarını anlık olarak işleyebilirsiniz.\n",
    "\n",
    "8. **Graf İşleme:** Spark GraphX, büyük çaplı graf verilerini işlemek ve analiz etmek için kullanılır.\n",
    "\n",
    "PySpark ile işe başlamak için, öncelikle bir Spark oturumu oluşturmanız gerekmektedir. Bu oturum, Spark bağlantısını kurmanıza ve Spark üzerinde işlem yapmanıza olanak sağlar. Daha sonra veri yükleme, veri işleme, analiz ve model oluşturma gibi adımları gerçekleştirebilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed0760",
   "metadata": {
    "id": "85ed0760"
   },
   "source": [
    "# Projemiz: Spark ile Büyük Veri olan \"Churn\" Tahmini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31786bdc",
   "metadata": {
    "id": "31786bdc"
   },
   "source": [
    "Spark oturumu açtıktan sonra izlenecek adımları aşağıdaki gibi özetleyebiliriz:\n",
    "Elbette, işte zamirleri kullanarak PySpark kullanarak Büyük Veri Müşteri Kaybı (Churn) tahmini projesinin adımları:\n",
    "\n",
    "1. **Veri Hazırlığı:**\n",
    "   - İlgili verileri toplayarak veri kaynaklarından verileri alacağız.\n",
    "   - Bu verileri PySpark DataFrame'e yükleyeceğiz veya oluşturacağız.\n",
    "   - Verileri incelemek ve işlem yapmak için keşifsel veri analizi (EDA) gerçekleştireceğiz. Eksik değerler, aykırı değerler ve kategorik değişkenler hakkında işlemler yapacağız.\n",
    "\n",
    "2. **Veri Ön İşleme:**\n",
    "   - Kategorik değişkenleri sayısal değerlere dönüştürmemiz gerekecek. Bunun için etiket kodlamayı veya tekil kodlamayı kullanabiliriz.\n",
    "   - Modelin performansını artırabilecek yeni özellikler oluşturmak için özellik seçimi ve mühendisliği yapacağız.\n",
    "\n",
    "3. **Veri Bölünmesi:**\n",
    "   - Veriyi eğitim ve test kümelerine ayıracağız. Genellikle verinin %70-80'ini eğitim, %20-30'unu test olarak ayırabiliriz.\n",
    "\n",
    "4. **Model Oluşturma:**\n",
    "   - GBTClassifier gibi bir makine öğrenimi modelini seçeceğiz ve ilgili parametreleri ayarlayacağız.\n",
    "   - Eğitim verilerini kullanarak modeli eğiteceğiz.\n",
    "\n",
    "5. **Model Değerlendirmesi:**\n",
    "   - Test verilerini kullanarak modelin performansını değerlendireceğiz. Doğruluk, hassasiyet, kesinlik, geri çağırma gibi metrikleri kullanacağız.\n",
    "   - Sonuçları anlamak için confusion matrix gibi görselleştirmeleri kullanacağız.\n",
    "\n",
    "6. **Model Ayarlaması ve Optimizasyon:**\n",
    "   - Modelin performansını artırmak için hiperparametre ayarlamaları yapacağız. GridSearch veya RandomizedSearch gibi yöntemleri kullanabiliriz.\n",
    "   - Aşırı öğrenmeyi önlemek için düzenleme (regularization) tekniklerini (örneğin, ağaç sayısını sınırlamak) uygulayabiliriz.\n",
    "\n",
    "7. **Sonuçların Sunumu:**\n",
    "   - Modelin sonuçlarını yönetim veya ilgili paydaşlarla paylaşmak için etkili bir sunum hazırlayacağız.\n",
    "   - Önemli özellikleri, işaretçileri ve modelin tahmin yeteneğini vurgulayacağız.\n",
    "\n",
    "8. **Üretim Ortamına Entegrasyon:**\n",
    "   - Başarılı bir model elde edersek, modeli üretim ortamına entegre etmek için gerekli adımları takip edeceğiz.\n",
    "   - Modeli kullanıma sunmak için gereken işlemleri gerçekleştireceğiz.\n",
    "\n",
    "9. **Sürekli İyileştirme:**\n",
    "   - Modeli düzenli olarak gözden geçirip yeni verilerle güncelleyeceğiz. Müşteri davranışı zamanla değişebilir, bu nedenle modelin güncelliğini sağlayacağız.\n",
    "\n",
    "Bu adımları takip ederek, PySpark kullanarak Büyük Veri Müşteri Kaybı tahmini projesini gerçekleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31f8bae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d31f8bae",
    "outputId": "097171c4-2839-4660-9c5a-b929f39006a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret\n",
      "  Downloading pycaret-3.0.4-py3-none-any.whl (484 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.4/484.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.34.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.7.1)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.66.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.23.5)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5.3)\n",
      "Requirement already satisfied: jinja2>=1.2 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.2)\n",
      "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn<1.3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.2.2)\n",
      "Collecting pyod>=1.0.8 (from pycaret)\n",
      "  Downloading pyod-1.1.0.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.10.1)\n",
      "Collecting category-encoders>=2.4.0 (from pycaret)\n",
      "  Downloading category_encoders-2.6.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.0.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.56.4)\n",
      "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.5)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (6.8.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.2.1)\n",
      "Collecting deprecation>=2.1.0 (from pycaret)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting xxhash (from pycaret)\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.7.1)\n",
      "Collecting scikit-plot>=0.3.7 (from pycaret)\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.15.0)\n",
      "Collecting kaleido>=0.2.1 (from pycaret)\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting schemdraw==0.15 (from pycaret)\n",
      "  Downloading schemdraw-0.15-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plotly-resampler>=0.8.3.1 (from pycaret)\n",
      "  Downloading plotly_resampler-0.9.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.14.0)\n",
      "Collecting sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1 (from pycaret)\n",
      "  Downloading sktime-0.22.0-py3-none-any.whl (17.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tbats>=1.1.3 (from pycaret)\n",
      "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pmdarima!=1.8.1,<3.0.0,>=1.8.0 (from pycaret)\n",
      "  Downloading pmdarima-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wurlitzer (from pycaret)\n",
      "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret) (0.5.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation>=2.1.0->pycaret) (23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.8.1->pycaret) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.16.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (67.7.2)\n",
      "Collecting jedi>=0.16 (from ipython>=5.5.0->pycaret)\n",
      "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (3.0.39)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (2.16.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->pycaret) (2.8.2)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (2.18.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (4.19.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (5.3.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.0->pycaret) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->pycaret) (8.2.3)\n",
      "Collecting dash<3.0.0,>=2.11.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash-2.12.1-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trace-updater>=0.0.8 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading trace_updater-0.0.9.1-py3-none-any.whl (185 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.2/185.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tsdownsample==0.1.2 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading tsdownsample-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (0.29.36)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (2.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod>=1.0.8->pycaret) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (2023.7.22)\n",
      "Collecting scikit-base<0.6.0 (from sktime!=0.17.1,!=0.17.2,!=0.18.0,>=0.16.1->pycaret)\n",
      "  Downloading scikit_base-0.5.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Flask<2.3.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.5)\n",
      "Collecting Werkzeug<2.3.0 (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dash-html-components==2.0.0 (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-table==5.0.0 (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (4.7.1)\n",
      "Collecting retrying (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Collecting ansi2html (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.5.7)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.9.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (3.10.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.0.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.24.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.3)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.11.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.7.1)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.6.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.4.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.1.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.21)\n",
      "Building wheels for collected packages: pyod\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyod: filename=pyod-1.1.0-py3-none-any.whl size=185329 sha256=c19645095d3b7e1132dae0663aaf941746ed81ea4124ac81361a47c4c73b7cfb\n",
      "  Stored in directory: /root/.cache/pip/wheels/36/8e/e2/e932956b10b843eb6be9eefa70b5c1bee7b561be14c423b136\n",
      "Successfully built pyod\n",
      "Installing collected packages: trace-updater, kaleido, dash-table, dash-html-components, dash-core-components, xxhash, wurlitzer, Werkzeug, tsdownsample, scikit-base, schemdraw, retrying, orjson, jedi, deprecation, ansi2html, sktime, scikit-plot, pyod, dash, pmdarima, plotly-resampler, category-encoders, tbats, pycaret\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.3.7\n",
      "    Uninstalling Werkzeug-2.3.7:\n",
      "      Successfully uninstalled Werkzeug-2.3.7\n",
      "Successfully installed Werkzeug-2.2.3 ansi2html-1.8.0 category-encoders-2.6.2 dash-2.12.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 jedi-0.19.0 kaleido-0.2.1 orjson-3.9.5 plotly-resampler-0.9.1 pmdarima-2.0.3 pycaret-3.0.4 pyod-1.1.0 retrying-1.3.4 schemdraw-0.15 scikit-base-0.5.1 scikit-plot-0.3.7 sktime-0.22.0 tbats-1.1.3 trace-updater-0.0.9.1 tsdownsample-0.1.2 wurlitzer-3.0.3 xxhash-3.3.0\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=7059f9903ab5d9cdbfd6214a527d87bafa82fcd6759b2a1d15a9e7f16f34f38a\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.4.1\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# İndirmeler\n",
    "!pip install pycaret\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a52b99c",
   "metadata": {
    "id": "7a52b99c"
   },
   "outputs": [],
   "source": [
    "# Kütüphaneler\n",
    "import findspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, GBTClassifier, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9f5ec",
   "metadata": {
    "id": "23e9f5ec"
   },
   "source": [
    "## 1. **Veri Hazırlığı:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74940b3",
   "metadata": {
    "id": "f74940b3"
   },
   "outputs": [],
   "source": [
    "# Spark oturumu açıyoruz:\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "MAX_MEMORY = \"10g\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Churn\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002918f",
   "metadata": {
    "id": "3002918f"
   },
   "source": [
    "Bu kod örneği PySpark ile bir Spark oturumu (Spark Session) oluşturmayı gösteriyor. Bir Spark oturumu, Spark işlemlerini ve uygulamalarını yürütmek için kullanılan temel arayüzdür. Kodun her bir bölümünü ayrıntılı bir şekilde açıklayalım:\n",
    "\n",
    "1. **MAX_MEMORY Tanımı:**\n",
    "   Bu kısım, bellek sınırlarını belirlemek için kullanılan bir sabiti tanımlar. `\"10g\"` ifadesi, 10 gigabayt bellek miktarını temsil eder. Bu, Spark oturumunda kullanılacak toplam bellek miktarını belirtir.\n",
    "\n",
    "2. **SparkSession Oluşturma:**\n",
    "   - `SparkSession`: Bu sınıf, Spark uygulamaları için temel giriş noktasıdır. Uygulamalarınızı yürütmek ve Spark'a erişmek için kullanılır.\n",
    "   - `.builder`: SparkSession oluşturmak için kullanılan bir yapılandırıcı nesnesi oluşturur.\n",
    "   - `.appName(\"Churn\")`: Uygulama adını belirtir. Bu isim Spark UI'da görünecektir.\n",
    "   - `.config(\"spark.executor.memory\", MAX_MEMORY)`: Bu yöntem, Spark yapılandırmasını ayarlar. Burada \"spark.executor.memory\" yapılandırmasını \"10g\" olarak ayarlıyoruz. Bu, her bir Spark işçi sürecine tahsis edilen bellek miktarını belirtir.\n",
    "   - `.config(\"spark.driver.memory\", MAX_MEMORY)`: Benzer şekilde, \"spark.driver.memory\" yapılandırmasını da \"10g\" olarak ayarlıyoruz. Bu, sürücü programın (ana işlem) kullanabileceği bellek miktarını belirtir.\n",
    "   - `.getOrCreate()`: Eğer mevcut bir Spark oturumu varsa, onu alır; yoksa yeni bir Spark oturumu oluşturur.\n",
    "\n",
    "Bu kodun amacı, yüksek düzeyde yapılandırılmış bir Spark oturumu oluşturmak ve bu oturumda tanımlanan bellek sınırlarını belirlemektir. Bellek sınırları, Spark işlemlerinin ve hesaplamalarının verimli ve dengeli bir şekilde yapılmasını sağlamak için önemlidir. Özellikle büyük veri işlemleri yürütüldüğünde, bellek ayarlarını doğru bir şekilde yapılandırmak büyük önem taşır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d034fc",
   "metadata": {
    "id": "55d034fc"
   },
   "outputs": [],
   "source": [
    "# Veriyi okuyoruz\n",
    "df= spark.read.format(\"csv\").option(\"header\",\"true\").load(\"churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413bcd69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "413bcd69",
    "outputId": "0af66f24-963f-4afa-83ae-01ac7342e234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "|  5|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|    1|\n",
      "|  6|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|    1|\n",
      "|  7|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|    1|\n",
      "|  8|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|    1|\n",
      "|  9|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|    1|\n",
      "| 10|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|    1|\n",
      "| 11|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|    1|\n",
      "| 12|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|    1|\n",
      "| 13|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|    1|\n",
      "| 14|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|    1|\n",
      "| 15|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|    1|\n",
      "| 16|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|    1|\n",
      "| 17|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|    1|\n",
      "| 18|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|    1|\n",
      "| 19|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|    1|\n",
      "+---+-------------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78a7a",
   "metadata": {
    "id": "22a78a7a"
   },
   "source": [
    "### EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a107fb14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a107fb14",
    "outputId": "ddac74e8-67ff-4f03-d3d0-118d1599de6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Satır sayısı\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d5a7718",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d5a7718",
    "outputId": "a1df03ec-0ae0-41f2-b0ba-8a01de12f8d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sutun Sayısı\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f98b33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44f98b33",
    "outputId": "93361d9c-9bc8-4852-ab26-090c1892221f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Total_Purchase: string (nullable = true)\n",
      " |-- Account_Manager: string (nullable = true)\n",
      " |-- Years: string (nullable = true)\n",
      " |-- Num_Sites: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# info gibi bilgiler için\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e332927",
   "metadata": {
    "id": "2e332927"
   },
   "outputs": [],
   "source": [
    "# Bu kod, _c0 adındaki bir sütunu index olarak yeniden adlandırmak için kullanılır.\n",
    "# Bu tür ad değişiklikleri, verinin daha iyi anlaşılabilir ve yönetilebilir olmasını sağlamak için yaygın olarak kullanılır.\n",
    "df=df.withColumnRenamed(\"_c0\",\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44d9f06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b44d9f06",
    "outputId": "5e31ed5d-db66-4fa0-efce-3dbdbe3c55ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Burada pthondaki unique gibi sutun içindeki benzersizliklere bakacağız.\n",
    "#Çünkü verinin tekrar edip etmediğini bilerek daha sıhhatli sonuçlara ulaşırız,\n",
    "#Names ı neden seçtik çünkü diğer sutunlarda benzerlik olabilir ama isim benzerliği nadir rastlanan bir durumdur.\n",
    "df.select(\"names\").distinct().count() #names sütununda benzesiz olan değerlerin sayısını hesaplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3d28bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc3d28bb",
    "outputId": "2e7520a9-16fa-4b16-84f5-1cbf6d986469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|           names|count|\n",
      "+----------------+-----+\n",
      "|   Jennifer Wood|    2|\n",
      "|    Patrick Bell|    1|\n",
      "|Patrick Robinson|    1|\n",
      "|   Chelsea Marsh|    1|\n",
      "|     John Barber|    1|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#900 olan veri 899 çıktığı için isimde bir tekrar etme sözkonusu onu bulmak için isimleri gruplandırma yapıyoruz.\n",
    "df.groupBy(\"names\").count().sort(\"count\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cdc781",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72cdc781",
    "outputId": "cbded19a-1535-45ca-f0d6-fcdd8929a3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|index|        Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|   22|Jennifer Wood|35.0|       9381.12|              1| 6.78|     11.0|    1|\n",
      "|  439|Jennifer Wood|48.0|      11585.16|              0| 4.61|      9.0|    0|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iki giriş olan Jennifer Wood'un sağlamasını yapıyoruz.\n",
    "df.filter(df[\"names\"] == \"Jennifer Wood\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679fafe3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "679fafe3",
    "outputId": "b533938a-c6c4-4a54-bc68-645244046c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|              age|   total_purchase|   account_manager|            years|         num_sites|              churn|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|              900|              900|               900|              900|               900|                900|\n",
      "|   mean|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|0.16666666666666666|\n",
      "| stddev|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969| 0.3728852122772358|\n",
      "|    min|             22.0|            100.0|                 0|              1.0|              10.0|                  0|\n",
      "|    max|             65.0|           9993.5|                 1|             9.15|               9.0|                  1|\n",
      "+-------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# İstatistiğine bakıyoruz\n",
    "df.select('age','total_purchase','account_manager','years','num_sites','churn').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b076924",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "8b076924",
    "outputId": "dcd58773-457c-495f-f62a-2c43d98c598e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c4bae068-06ea-4f14-894a-0fd21b5846be\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>900</td>\n",
       "      <td>449.5</td>\n",
       "      <td>259.95191863111916</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Names</th>\n",
       "      <td>900</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aaron King</td>\n",
       "      <td>Zachary Walsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>900</td>\n",
       "      <td>41.81666666666667</td>\n",
       "      <td>6.127560416916251</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Purchase</th>\n",
       "      <td>900</td>\n",
       "      <td>10062.82403333334</td>\n",
       "      <td>2408.644531858096</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9993.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account_Manager</th>\n",
       "      <td>900</td>\n",
       "      <td>0.4811111111111111</td>\n",
       "      <td>0.4999208935073339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <td>900</td>\n",
       "      <td>5.27315555555555</td>\n",
       "      <td>1.274449013194616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Sites</th>\n",
       "      <td>900</td>\n",
       "      <td>8.587777777777777</td>\n",
       "      <td>1.7648355920350969</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn</th>\n",
       "      <td>900</td>\n",
       "      <td>0.16666666666666666</td>\n",
       "      <td>0.3728852122772358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4bae068-06ea-4f14-894a-0fd21b5846be')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c4bae068-06ea-4f14-894a-0fd21b5846be button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c4bae068-06ea-4f14-894a-0fd21b5846be');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-168f92e1-b285-4d7a-a941-4f8270e9d7cf\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-168f92e1-b285-4d7a-a941-4f8270e9d7cf')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-168f92e1-b285-4d7a-a941-4f8270e9d7cf button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                     0                    1                   2           3  \\\n",
       "summary          count                 mean              stddev         min   \n",
       "index              900                449.5  259.95191863111916           0   \n",
       "Names              900                 None                None  Aaron King   \n",
       "Age                900    41.81666666666667   6.127560416916251        22.0   \n",
       "Total_Purchase     900    10062.82403333334   2408.644531858096       100.0   \n",
       "Account_Manager    900   0.4811111111111111  0.4999208935073339           0   \n",
       "Years              900     5.27315555555555   1.274449013194616         1.0   \n",
       "Num_Sites          900    8.587777777777777  1.7648355920350969        10.0   \n",
       "Churn              900  0.16666666666666666  0.3728852122772358           0   \n",
       "\n",
       "                             4  \n",
       "summary                    max  \n",
       "index                       99  \n",
       "Names            Zachary Walsh  \n",
       "Age                       65.0  \n",
       "Total_Purchase          9993.5  \n",
       "Account_Manager              1  \n",
       "Years                     9.15  \n",
       "Num_Sites                  9.0  \n",
       "Churn                        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aynı veriyi pandas tablosunda görüntülemek\n",
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e699f185",
   "metadata": {
    "id": "e699f185"
   },
   "outputs": [],
   "source": [
    "# boş verileri çıkarmak için\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36cd29fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36cd29fd",
    "outputId": "00e59d98-c751-42cd-fbce-7ccfb4f49d26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index', 'string'),\n",
       " ('Names', 'string'),\n",
       " ('Age', 'string'),\n",
       " ('Total_Purchase', 'string'),\n",
       " ('Account_Manager', 'string'),\n",
       " ('Years', 'string'),\n",
       " ('Num_Sites', 'string'),\n",
       " ('Churn', 'string')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri tiplerine bakacağız\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d6acb",
   "metadata": {
    "id": "338d6acb"
   },
   "source": [
    "## 2. **Veri Ön İşleme:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59f21c",
   "metadata": {
    "id": "ef59f21c"
   },
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff230e36",
   "metadata": {
    "id": "ff230e36"
   },
   "outputs": [],
   "source": [
    "# Hedef sutunumuz olan \"Churn\"u Classification algoritmasına vermeden önce int e çevirmeliyiz ki işleyebilsin.\n",
    "# \"Churn\" adlı kategorik sütunu sayısal etiketlere dönüştürüp, \"label\" adında yeni bir sütun oluşturulur.\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "stringIndexer=StringIndexer(inputCol=\"Churn\", outputCol=\"churn_int\")\n",
    "\n",
    "indexed=stringIndexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a64773f",
   "metadata": {
    "id": "8a64773f"
   },
   "outputs": [],
   "source": [
    "# Çevirdiğimizi df'ye atıyoruz\n",
    "df = indexed.withColumn(\"churn_int\",indexed.churn_int.cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edcb3828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edcb3828",
    "outputId": "a09a6a70-c34a-4dd6-cb73-d296d91ab1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index', 'string'),\n",
       " ('Names', 'string'),\n",
       " ('Age', 'string'),\n",
       " ('Total_Purchase', 'string'),\n",
       " ('Account_Manager', 'string'),\n",
       " ('Years', 'string'),\n",
       " ('Num_Sites', 'string'),\n",
       " ('Churn', 'string'),\n",
       " ('churn_int', 'int')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kontrol edelim\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bea6e9b",
   "metadata": {
    "id": "9bea6e9b"
   },
   "outputs": [],
   "source": [
    "# Churn dışındaki diğer sutunlar için de type değiştirme yapıyoruz ama Sadece veri tipi değişikliği var.\n",
    "# Yeniden adlandırma ayrı bir işlem olarak gerçekleştirilmez.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df=df.select([col(column).cast(\"integer\").alias(column)\n",
    "              if column in [\"index\",\"Age\",'Total_Purchase','Account_Manager','Years','Num_Sites','Churn'] else col(column)\n",
    "              for column in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b5159bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b5159bd",
    "outputId": "f934e0ef-d8b7-4164-e1e0-b928ef524f27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index', 'int'),\n",
       " ('Names', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Total_Purchase', 'int'),\n",
       " ('Account_Manager', 'int'),\n",
       " ('Years', 'int'),\n",
       " ('Num_Sites', 'int'),\n",
       " ('Churn', 'int'),\n",
       " ('churn_int', 'int')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "# artık bütün veriler sayısal değerlere dönüştü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b590b610",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b590b610",
    "outputId": "f242d6d5-d8f0-4543-c004-32366ea65e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+---+--------------+---------------+-----+---------+-----+---------+--------------------+\n",
      "|index|              Names|Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|churn_int|            features|\n",
      "+-----+-------------------+---+--------------+---------------+-----+---------+-----+---------+--------------------+\n",
      "|    0|   Cameron Williams| 42|         11066|              0|    7|        8|    1|        1|[42.0,11066.0,0.0...|\n",
      "|    1|      Kevin Mueller| 41|         11916|              0|    6|       11|    1|        1|[41.0,11916.0,0.0...|\n",
      "|    2|        Eric Lozano| 38|         12884|              0|    6|       12|    1|        1|[38.0,12884.0,0.0...|\n",
      "|    3|      Phillip White| 42|          8010|              0|    6|       10|    1|        1|[42.0,8010.0,0.0,...|\n",
      "|    4|     Cynthia Norton| 37|          9191|              0|    5|        9|    1|        1|[37.0,9191.0,0.0,...|\n",
      "|    5|   Jessica Williams| 48|         10356|              0|    5|        8|    1|        1|[48.0,10356.0,0.0...|\n",
      "|    6|        Eric Butler| 44|         11331|              1|    5|       11|    1|        1|[44.0,11331.0,1.0...|\n",
      "|    7|      Zachary Walsh| 32|          9885|              1|    6|        9|    1|        1|[32.0,9885.0,1.0,...|\n",
      "|    8|        Ashlee Carr| 43|         14062|              1|    5|       11|    1|        1|[43.0,14062.0,1.0...|\n",
      "|    9|     Jennifer Lynch| 40|          8066|              1|    7|       11|    1|        1|[40.0,8066.0,1.0,...|\n",
      "|   10|       Paula Harris| 30|         11575|              1|    5|        8|    1|        1|[30.0,11575.0,1.0...|\n",
      "|   11|     Bruce Phillips| 45|          8771|              1|    6|       11|    1|        1|[45.0,8771.0,1.0,...|\n",
      "|   12|       Craig Garner| 45|          8988|              1|    4|       11|    1|        1|[45.0,8988.0,1.0,...|\n",
      "|   13|       Nicole Olson| 40|          8283|              1|    5|       13|    1|        1|[40.0,8283.0,1.0,...|\n",
      "|   14|     Harold Griffin| 41|          6569|              1|    4|       11|    1|        1|[41.0,6569.0,1.0,...|\n",
      "|   15|       James Wright| 38|         10494|              1|    6|       12|    1|        1|[38.0,10494.0,1.0...|\n",
      "|   16|      Doris Wilkins| 45|          8213|              1|    7|       11|    1|        1|[45.0,8213.0,1.0,...|\n",
      "|   17|Katherine Carpenter| 43|         11226|              0|    8|       12|    1|        1|[43.0,11226.0,0.0...|\n",
      "|   18|     Lindsay Martin| 53|          5515|              0|    6|        8|    1|        1|[53.0,5515.0,0.0,...|\n",
      "|   19|        Kathy Curry| 46|          8046|              1|    5|        8|    1|        1|[46.0,8046.0,1.0,...|\n",
      "+-----+-------------------+---+--------------+---------------+-----+---------+-----+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------+\n",
      "|            features|churn_int|\n",
      "+--------------------+---------+\n",
      "|[42.0,11066.0,0.0...|        1|\n",
      "|[41.0,11916.0,0.0...|        1|\n",
      "|[38.0,12884.0,0.0...|        1|\n",
      "|[42.0,8010.0,0.0,...|        1|\n",
      "|[37.0,9191.0,0.0,...|        1|\n",
      "|[48.0,10356.0,0.0...|        1|\n",
      "|[44.0,11331.0,1.0...|        1|\n",
      "|[32.0,9885.0,1.0,...|        1|\n",
      "|[43.0,14062.0,1.0...|        1|\n",
      "|[40.0,8066.0,1.0,...|        1|\n",
      "|[30.0,11575.0,1.0...|        1|\n",
      "|[45.0,8771.0,1.0,...|        1|\n",
      "|[45.0,8988.0,1.0,...|        1|\n",
      "|[40.0,8283.0,1.0,...|        1|\n",
      "|[41.0,6569.0,1.0,...|        1|\n",
      "|[38.0,10494.0,1.0...|        1|\n",
      "|[45.0,8213.0,1.0,...|        1|\n",
      "|[43.0,11226.0,0.0...|        1|\n",
      "|[53.0,5515.0,0.0,...|        1|\n",
      "|[46.0,8046.0,1.0,...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hedefimiz dışındaki tüm sutunları bir vektöre atıyoruz\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "depended=[\"Age\",'Total_Purchase','Account_Manager','Years','Num_Sites']\n",
    "vectorAssembler=VectorAssembler(inputCols=depended, outputCol=\"features\")\n",
    "df_vect=vectorAssembler.transform(df)\n",
    "df_vect.show()\n",
    "final_df=df_vect.select(\"features\",\"churn_int\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b297cba",
   "metadata": {
    "id": "7b297cba"
   },
   "source": [
    "Yukarıdaki hedef dışındakileri vektöre atamanın faydalarını şöyle sıralayabilirz:\n",
    "\n",
    "Veriyi Hazırlama: Birçok makine öğrenimi algoritması, bağımsız değişkenleri vektörler veya matrisler olarak bekler. Bu kodlar, belirtilen bağımsız değişkenleri bir araya getirerek, veriyi algoritmaya hazır bir formatta dönüştürmek amacıyla kullanılır.\n",
    "\n",
    "Özellik Mühendisliği: Bağımsız değişkenlerin özelliklerini vektörel bir özellikte birleştirerek, modelin daha fazla bilgiyle eğitilmesini sağlar. Özellikle bazı modeller, bağımsız değişkenlerin etkileşimlerini veya kombinasyonlarını daha iyi yakalayarak daha iyi sonuçlar üretebilir.\n",
    "\n",
    "Veri Boyutunu Azaltma: Eğer çok sayıda bağımsız değişkeniniz varsa, bunları bir vektörel özellik olarak birleştirerek veri boyutunu azaltabilirsiniz. Bu, gereksiz boyut artışını engelleyerek, daha hızlı ve daha verimli model eğitimi sağlar.\n",
    "\n",
    "Bazı Algoritmalar için Gereklilik: Özellikle bazı algoritmalar, bağımsız değişkenleri vektör formatında almayı bekler. Bu kodlar, bu tür algoritmalarla uyumlu hale getirir.\n",
    "\n",
    "Kodun Okunabilirliği: Bu kodlar, özellik mühendisliği adımını daha kolay anlaşılır ve düzenli bir şekilde gerçekleştirmenizi sağlar.\n",
    "\n",
    "Sonuç olarak, bu kodlar, belirtilen bağımsız değişkenleri birleştirip bir vektörel özellik sütunu oluşturarak veriyi modele hazır hale getirir. Bu tür bir özellik mühendisliği, genellikle modelinizin performansını artırmanıza ve daha iyi sonuçlar elde etmenize yardımcı olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "526855b0",
   "metadata": {
    "id": "526855b0"
   },
   "outputs": [],
   "source": [
    "final_df=df.withColumn(\"age_sqrt\",df.Age**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612da490",
   "metadata": {
    "id": "612da490"
   },
   "source": [
    "Bu kod, DataFrame'deki \"Age\" (yaş) sütunundaki değerleri kullanarak yeni bir sütun olan \"age_sqrt\" (yaşın karesi) sütununu oluşturmak için kullanılır. Bu tür özellik mühendisliği işlemleri, veriyi daha iyi anlamak, modele daha fazla bilgi sağlamak veya bazı modellerin performansını artırmak amacıyla gerçekleştirilir. İşte kodun amaçları ve faydaları:\n",
    "\n",
    "1. **Model İçin Daha İyi Özellik Sağlama:** Bazı durumlarda, yaş değeriyle birlikte yaşın karesi de modelinize daha fazla bilgi sağlayabilir. Örneğin, bazı davranışlar yaşın karesiyle daha iyi açıklanabilir. Model, yaşın karesini kullanarak daha karmaşık ilişkileri yakalamak veya bazı örüntüleri keşfetmek için daha iyi bir performans gösterebilir.\n",
    "\n",
    "2. **Non-Lineer İlişkileri Temsil Etme:** Modeliniz, sadece yaşın kendisi yerine yaşın karesi ile daha iyi non-lineer ilişkileri temsil edebilir. Özellikle doğrusal olmayan ilişkileri modellemek için bu tür özellikleri kullanmak faydalı olabilir.\n",
    "\n",
    "3. **Azalan Önemli Etki:** Yaşın karesi, yaş arttıkça yaşın kendisinin etkisinin azaldığı bir durumu temsil edebilir. Örneğin, yaşın gençken daha belirgin olduğu bir etki sonrasında yaşın artmasıyla etkisinin azaldığı bir senaryo düşünülebilir. Bu tür durumları yakalamak için bu tür dönüşümler yapmak yararlı olabilir.\n",
    "\n",
    "4. **Hem Sayısal Hem de Kategorik Değerler İçin Uygunluk:** Yaş değeri kategorik olmadığından ve genellikle sürekli bir değişken olduğundan, yaşın karesi gibi türetilmiş özellikler bu tür durumlar için daha uygundur.\n",
    "\n",
    "Ancak, her durumda özellik mühendisliği yapmadan önce dikkatli bir analiz ve modelinize uygunluğunu değerlendirmek önemlidir. Özellikle gereksiz veya anlamsız özellikler modelinizi karmaşıklaştırabilir ve performansını düşürebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee867a",
   "metadata": {
    "id": "64ee867a"
   },
   "source": [
    "## 3. **Veri Bölünmesi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f1a41ad",
   "metadata": {
    "id": "7f1a41ad"
   },
   "outputs": [],
   "source": [
    "(traindf, testdf)=final_df.randomSplit([0.7,0.3],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d895a8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d895a8e",
    "outputId": "3c6b49a4-9c64-4fdf-b751-30600a9c8880"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3szS2zad2tGK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3szS2zad2tGK",
    "outputId": "71b8c28a-40ba-4772-897f-f082823723df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|churn_int|\n",
      "+--------------------+---------+\n",
      "|[22.0,11254.0,1.0...|        0|\n",
      "|[25.0,9672.0,0.0,...|        0|\n",
      "|[26.0,8939.0,0.0,...|        0|\n",
      "|[27.0,8628.0,1.0,...|        0|\n",
      "|[28.0,8670.0,0.0,...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traindf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5fe5eab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5fe5eab",
    "outputId": "da590dfb-ea26-40c3-9ff8-f8ca46cf30cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f764b4c",
   "metadata": {
    "id": "5f764b4c"
   },
   "source": [
    "## 4. **Model Oluşturma:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2981c1c7",
   "metadata": {
    "id": "2981c1c7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccd697bb",
   "metadata": {
    "id": "ccd697bb"
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxIter=70,maxDepth=20,featuresCol=\"features\",labelCol=\"churn_int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0aa914d",
   "metadata": {
    "id": "f0aa914d"
   },
   "outputs": [],
   "source": [
    "gbt_model = gbt.fit(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2643f272",
   "metadata": {
    "id": "2643f272"
   },
   "outputs": [],
   "source": [
    "pred = gbt_model.transform(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1a7b866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1a7b866",
    "outputId": "cdbf3318-1938-468e-d991-6eb6ae1586f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+----------+\n",
      "|            features|churn_int|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------+--------------------+--------------------+----------+\n",
      "|[26.0,8787.0,1.0,...|        1|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[28.0,9090.0,1.0,...|        0|[-2.0577731996618...|[0.01605505172522...|       1.0|\n",
      "|[28.0,11204.0,0.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[28.0,11245.0,0.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[29.0,9617.0,0.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[29.0,10203.0,1.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[29.0,11274.0,1.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[30.0,6744.0,0.0,...|        0|[-2.0577731996618...|[0.01605505172522...|       1.0|\n",
      "|[30.0,8403.0,1.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[30.0,8874.0,0.0,...|        0|[-2.0577731996618...|[0.01605505172522...|       1.0|\n",
      "|[30.0,10183.0,1.0...|        0|[-2.0577731996618...|[0.01605505172522...|       1.0|\n",
      "|[30.0,12788.0,0.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[30.0,13473.0,0.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[31.0,5304.0,0.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[31.0,7073.0,0.0,...|        0|[-2.0577731996618...|[0.01605505172522...|       1.0|\n",
      "|[31.0,8829.0,1.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[31.0,9574.0,0.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[31.0,11743.0,0.0...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[32.0,6367.0,1.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "|[32.0,7896.0,0.0,...|        0|[2.05777319966183...|[0.98394494827477...|       0.0|\n",
      "+--------------------+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81b28f",
   "metadata": {
    "id": "0e81b28f"
   },
   "source": [
    "## 5. **Model Değerlendirmesi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d132aa79",
   "metadata": {
    "id": "d132aa79"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"churn_int\",\n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdc8c63a",
   "metadata": {
    "id": "bdc8c63a"
   },
   "outputs": [],
   "source": [
    "accuracy=evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c374969",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c374969",
    "outputId": "458d7b99-ab85-4514-f4e7-ba3526181b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583690987124464"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b9ae9",
   "metadata": {
    "id": "4d5b9ae9"
   },
   "source": [
    "## 6. **Model Doğrulama:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2ad8a",
   "metadata": {
    "id": "9da2ad8a"
   },
   "source": [
    "Bu kod, çapraz doğrulama için bir Gradient Boosted Trees sınıflandırma modeli oluştururken denenecek olan farklı \"maxIter\" ve \"maxDepth\" parametre kombinasyonlarını belirler. Bu kombinasyonlar çapraz doğrulama işlemi sırasında modelin farklı parametre ayarlarıyla performansını değerlendirmenizi sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bac0069",
   "metadata": {
    "id": "1bac0069"
   },
   "outputs": [],
   "source": [
    "gbt_cv=GBTClassifier(featuresCol=\"features\",labelCol=\"churn_int\")\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "      .addGrid(gbt.maxIter, [10,20]) \\\n",
    "      .addGrid(gbt.maxDepth,[5,10]) \\\n",
    "      .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b056820",
   "metadata": {
    "id": "9b056820"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "cv=CrossValidator(estimator=gbt_cv,\n",
    "                  estimatorParamMaps=paramGrid,\n",
    "                  evaluator=evaluator,\n",
    "                  numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97934bd2",
   "metadata": {
    "id": "97934bd2"
   },
   "outputs": [],
   "source": [
    "cvModel=cv.fit(traindf)\n",
    "\n",
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5fedc36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5fedc36",
    "outputId": "911357c2-2267-479b-cc76-ad80e93f5a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test verilerinin doğruluğu:  0.8497854077253219\n"
     ]
    }
   ],
   "source": [
    "pred2 = bestModel.transform(testdf)\n",
    "\n",
    "accuracy = evaluator.evaluate(pred2)\n",
    "\n",
    "print(\"Test verilerinin doğruluğu: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b59406",
   "metadata": {
    "id": "36b59406"
   },
   "source": [
    "## 7. **Sonuçların Sunumu:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cgz6xWoq7fr9",
   "metadata": {
    "id": "Cgz6xWoq7fr9"
   },
   "source": [
    "Sonuç olarak bu proje kapsamında, PySpark kullanarak büyük veri üzerinde churn tahmini gerçekleştiren bir makine öğrenimi modeli oluşturduk. Veriyi okuma, ön işleme, özellik mühendisliği, model oluşturma ve hiperparametre ayarı gibi adımları takip ettik. Oluşturduğumuz Gradient Boosted Trees (GBT) sınıflandırma modelini farklı hiperparametre kombinasyonlarıyla çapraz doğrulama yöntemiyle değerlendirdik. Sonuçlarımızı MulticlassClassificationEvaluator kullanarak doğruluk metriği üzerinden değerlendirdik. Bu proje, büyük veri setleri üzerinde PySpark'ın yeteneklerini kullanarak veri analizi ve makine öğrenimi uygulamalarını gerçekleştirebileceğimizi gösterdi. Projede edindiğimiz deneyimle, gelecekteki büyük veri projelerine daha iyi yaklaşabileceğimiz ve daha gelişmiş analizler gerçekleştirebileceğimiz bir temel oluşturduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8qKhgP-7m-R",
   "metadata": {
    "id": "n8qKhgP-7m-R"
   },
   "outputs": [],
   "source": [
    "# Eğitilen GBT modelini seçip\n",
    "trained_model = cvModel.bestModel\n",
    "\n",
    "# Modeli \"11-Spark Big Data Machine Learning\" adlı dosyaya kaydet\n",
    "saved_model = \"Project Based Learning Level-2/11-Spark Big Data Machine Learning/my_model\"\n",
    "trained_model.save(saved_model)\n",
    "\n",
    "# Kaydedilen modeli yüklemek için:\n",
    "# loaded_model = GBTClassifierModel.load(saved_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
